\documentclass[12pt]{article}
\usepackage{natbib}
\usepackage{color}
\usepackage[dvipsnames,svgnames*]{xcolor}
\usepackage{array}
\usepackage[colorlinks=TRUE, linkcolor=blue]{hyperref}
\usepackage{wrapfig,float}
\usepackage[font=small,skip=5pt]{caption}
\usepackage{subcaption}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{dsfont}
\usepackage{amsthm}
\usepackage{amsfonts}
\usepackage{url}
\usepackage{ulem}
\usepackage[section]{placeins}
\usepackage{afterpage}
\usepackage{bbm}

\graphicspath{{images/}}
\DeclareGraphicsRule{.tif}{png}{.png}{`convert #1 `dirname #1`/`basename #1 .tif`.png}

\newtheorem{thm}{Theorem}[section]
\newtheorem{dfn}{Definition}[section]
\newtheorem{cor}{Corollary}[thm]
\newtheorem{con}{Conjecture}[thm]

% NOTE: To produce blinded version, replace "0" with "1" below.
\newcommand{\blind}{0}

\addtolength{\oddsidemargin}{-.5in}%
\addtolength{\evensidemargin}{-.5in}%
\addtolength{\textwidth}{1in}%
\addtolength{\textheight}{1.3in}%
\addtolength{\topmargin}{-.8in}%

\begin{document}

\def\spacingset#1{\renewcommand{\baselinestretch}%
{#1}\small\normalsize} \spacingset{1}

\title{\bf Supplementary Material: Comparing the Power of Plot Designs to Reveal Correlation}

\if0\blind
{
\author{Nathaniel Tomasetti and Dianne Cook\\
Department of Econometrics and Business Statistics, Monash University\\
}
  \maketitle
} \fi
\if1\blind
{
  \bigskip
  \bigskip
  \bigskip
  \begin{center}
    {\LARGE\bf Supplementary Material: Comparing the Power of Plot Designs to Reveal Correlation}
\end{center}
  \medskip
} \fi

\tableofcontents

<<setup, echo=FALSE, results='asis', message=FALSE, error=FALSE, warning=FALSE>>=
library(maps)
library(ggplot2)
library(dplyr)
library(tidyr)
full <- read.csv("full.csv", row.names=1, stringsAsFactors = FALSE) ##MTurk evaluations
prediction <- read.csv("sas/predfit.csv") ##Large file, very slow, fitted data from SAS
time.fit <- read.csv("sas/time.csv") ##coefficients for time model from SAS
powercoef <- read.csv("sas/PowerEstimates.csv") ##coefficients for power model from SAS

full <- full %>% mutate(design = ifelse(test_param ==1, "Overlaid Lines", "Scatterplot"),
                         r = round(correlation, 1),
                         rsgn = ifelse(r >= 0, 1, 0),
                         rabs = abs(r),
                         alpha = log(0.05/0.95),
                         attempts = sapply(strsplit(as.character(full$response_0), ","), length), 
                         ##count number of selections in response_0 column
                         weights = 1/attempts)

full$subj_id <- factor(full$nick_name, labels=1:212)
y <- data.frame(table(full$subj_id))
keep <- y$Var1[y$Freq>9]
full.sub <- filter(full, subj_id %in% keep) 
full.sub <- Reduce(rbind, by(full.sub, full.sub$subj_id, head, n=10))
##Remove subjects with less than 10 evaluations. If more than 10, keep only first 10.

full <- full %>%  transform(response_0= strsplit(as.character(response_0), ",")) %>% unnest(response_0) %>%
  ##split multiple selections in response_0 into different rows
  mutate(correct = ifelse(response_0 == actual_location, 1, 0), 
         score = ifelse(correct==1, (20-attempts)/19, 0)) %>%
  select(subj_id, correct, score, r, rsgn, rabs, smoothed, n, design, log_time, response_0,
         actual_location, pic_id, choice_reason, attempts, weights, alpha, conf_level)

full.sub <- full.sub %>% transform(response_0= strsplit(as.character(response_0), ",")) %>% unnest(response_0) %>%
  mutate(correct = ifelse(response_0 == actual_location, 1, 0), 
         score = ifelse(correct==1, (20-attempts)/19, 0)) %>%
  select(subj_id, correct, score, r, rsgn, rabs, smoothed, n, design, log_time, response_0,
         actual_location, pic_id, choice_reason, attempts, weights, alpha, conf_level)

bylineup <- summarise(group_by(full, pic_id, n, smoothed, design, r, actual_location), total=sum(score), correct=sum(correct), evals=sum(weights))
bylineup <- mutate(bylineup, percent = total/evals)
bylineup.sub <- summarise(group_by(full.sub, pic_id), total=sum(score), evals=sum(weights))
bylineup.sub <- mutate(bylineup.sub, percent = total/evals)

colnames(prediction) <- c("rabs", "t", "alpha", "rsgn", "smoothed", "design", "subj_id", "weights", "detected", "log_time", "RandomEf", "FixedEf", "residual")
prediction <- mutate(prediction, r = ifelse(rsgn==1, rabs, -rabs),
                     design = ifelse(design==0, "Overlaid Lines", "Scatterplot"), 
                     design = ifelse(smoothed==1, paste0(design, " (Smoothed)"), design),  
                     diff = round(RandomEf - FixedEf,5))
@

\section{Subject Demographics}

\begin{figure}[htbp]
\centering
<<map, dependson='setup', echo=FALSE, results='asis', message=FALSE, error=FALSE, warning=FALSE, fig.height=3>>=
location <- read.csv("location.csv")
map.dat <- map_data("world")
ggplot() + geom_polygon(aes(long,lat, group=group), fill="grey65", data=map.dat) + theme_bw() +
  geom_point(data=location, aes(x=lon, y=lat, colour= "blue")) +scale_colour_manual(values=c("#FF5500", "#00FFFF")) + theme(aspect.ratio = 0.67, axis.text=element_blank(), axis.title=element_blank(), legend.position="none")
@
\caption{The location of the recruited subjects. The majority reside in North America but some are spread around other countries in Central America, Europe and Asia.}
\label{map}
\end{figure}

\begin{figure}[htbp]
\centering
<<users, dependson='setup', echo=FALSE, results='asis', message=FALSE, error=FALSE, warning=FALSE>>=
users <- read.csv("turk18_users.csv")
users$gender <- ifelse(users$gender==1, "Male", "Female")
ggplot(data=users, aes(x=factor(age), fill=factor(academic_study))) + geom_bar() + facet_wrap(~gender) +
  scale_fill_manual(values=c("#550000", "#883388", "#1133FF", "#FF9933", "#555555"))
@
\caption{Age and education by gender. Most subjects are in the younger brackets and there are more males than females}
\label{ageed}
\end{figure}


\section{Descriptive Statistics of Evaluations}

\begin{table}[htp]
\caption{The true plot detections / evaluations for each lineup in the data collection. Lineups with the same factor combination are seperated by row. Results ignore multiple selection and any removed evaluations. True plot correlation is on the x axis and t is on the y axis.}
\label{tabeval}
\centering
<<answertables, dependson='setup', echo=FALSE, results='asis', message=FALSE, error=FALSE, warning=FALSE>>=
turk.tbl <- select(bylineup, design, smoothed, r, n, correct, evals)
turk.tbl$result <- paste(round(turk.tbl$correct, 0), turk.tbl$evals, sep="/")
turk.tbl <- turk.tbl[order(turk.tbl$r, turk.tbl$n),]
scatter.uns <- data.frame(c(12, "", "", 24, "", "", 48, "", "", 96, "", ""), matrix(subset(turk.tbl, smoothed==0 & design=="Scatterplot")$result, ncol=8))
scatter.sm <- data.frame(c(12, "", "", 24, "", "", 48, "", "", 96, "", ""), matrix(subset(turk.tbl, smoothed==1 & design=="Scatterplot")$result, ncol=8))
line.uns <- data.frame(c(12, "", "", 24, "", "", 48, "", "", 96, "", ""), matrix(subset(turk.tbl, smoothed==0 & design=="Overlaid Lines")$result, ncol=8))
line.sm <- data.frame(c(12, "", "", 24, "", "", 48, "", "", 96, "", ""), matrix(subset(turk.tbl, smoothed==1 & design=="Overlaid Lines")$result, ncol=8))
colnames(scatter.uns) <- c("Unsmoothed Scatterplot", "-0.9", "-0.7", "-0.5", "-0.3", "0.3", "0.5", "0.7", "0.9")
colnames(scatter.sm) <- c("Smoothed Scatterplot","-0.9", "-0.7", "-0.5", "-0.3", "0.3", "0.5", "0.7", "0.9")
colnames(line.uns) <- c("Unsmoothed Overlaid Lines","-0.9", "-0.7", "-0.5", "-0.3", "0.3", "0.5", "0.7", "0.9")
colnames(line.sm) <- c("Smoothed Overlaid Lines","-0.9", "-0.7", "-0.5", "-0.3", "0.3", "0.5", "0.7", "0.9")
kable(scatter.uns, format="latex")
@
\end{table}
\begin{table}
\centering
<<answertables2, dependson='setup', echo=FALSE, results='asis', message=FALSE, error=FALSE, warning=FALSE>>=
kable(scatter.sm, format="latex")
@
\end{table}
\begin{table}
\centering
<<answertables3, dependson='setup', echo=FALSE, results='asis', message=FALSE, error=FALSE, warning=FALSE>>=
kable(line.uns, format="latex")
@
\end{table}
\begin{table}
\centering
<<answertables4, dependson='setup', echo=FALSE, results='asis', message=FALSE, error=FALSE, warning=FALSE>>=
kable(line.sm, format="latex")
@
\end{table}


\begin{figure}[htbp]
\centering
<<choices, dependson='setup', echo=FALSE, results='asis', message=FALSE, error=FALSE, warning=FALSE>>=
full$choice_reason <-sapply(strsplit(as.character(unlist(full$choice_reason)), "[^0-9]+"), "[[", 1)
choice <- full %>% transform(choice_reason= strsplit(as.character(choice_reason), "")) %>% unnest(choice_reason)
choice$rsgn <- factor(choice$rsgn, labels=c("r -","r +"))
choice$correct <- factor(choice$correct, labels=c("Did not detect", "Detected"))
ggplot(data=choice, aes(x=choice_reason, fill=correct)) + geom_bar() + facet_grid(design~rsgn) +
  theme(legend.position="bottom", axis.title=element_blank()) + scale_fill_discrete(name="True Plot")
@
\caption{Reasons given for plot selection}
\label{reasons}
\end{figure}

\begin{figure}[htbp]
\centering 
<<avscore, dependson='setup', echo=FALSE, results='asis', message=FALSE, error=FALSE, warning=FALSE>>= 
subjplot <- summarise(group_by(full.sub, subj_id), eval=sum(weights), total = sum(score))
subjplot <- mutate(subjplot, avscore= total/eval)
ggplot(data=subjplot, aes(x=avscore)) + geom_histogram(binwidth=0.05)
@
\caption{Average score of subjects included in modelling}
\label{avscore}
\end{figure}

\begin{figure}[htbp]
\centering
<<multiselect, dependson='setup', echo=FALSE, results='asis', message=FALSE, error=FALSE, warning=FALSE>>=
m.select <- summarise(group_by(subset(full.sub, attempts>1), subj_id, pic_id), attempts=max(attempts))
m.freq <- data.frame(table(m.select$pic_id))
m.lineup <- merge(m.freq, bylineup, by.x="Var1", by.y="pic_id")
ggplot(data=m.lineup) + geom_bar(aes(x=factor(r), fill=design), binwidth=0.2) + facet_grid(n~smoothed) + labs(y="Count", x="True plot correlation")
@
\caption{Characteristics of lineups with at least one subject making multiple selections}
\label{lineupmulti}
\end{figure}

\begin{table}[htbp]
\caption{Number of selections per lineup evaluation. The subject with the most selections is reported.}
\label{table}
<<tabattempts, dependson='setup', echo=FALSE, results='asis', message=FALSE, error=FALSE, warning=FALSE>>=
attempts <- summarise(group_by(full.sub, subj_id, pic_id), attempts = max(attempts))
attempts.table <- data.frame(table(attempts$attempts))
attempts.table$most <- c(0,0,0,5,3,1,1)
colnames(attempts.table) <- c("Selections", "Whole Sample", "Subject 123")
kable(attempts.table, format="latex")
@
\end{table}


\begin{figure}[htbp]
\centering
<<multiattempts, dependson='setup', echo=FALSE, results='asis', message=FALSE, error=FALSE, warning=FALSE>>=
ggplot(data=attempts) + geom_bar(aes(x=as.factor(attempts))) + labs(x="Number of selections", y=NULL)
@
\caption{Histogram of table~\ref{table}}
\label{attemptshist}
\end{figure}


\section{Model Validation}

\begin{figure}[htbp]
  \centering
<<residuals, dependson='setup', fig.height=4, fig.width=6, out.width='0.7\\textwidth', echo=FALSE, warning=FALSE, message=FALSE, error=FALSE>>=
glmm.resid <- subset(prediction, detected==0 | detected==1)
ggplot(data=glmm.resid) + geom_histogram(aes(y=..density.., x=residual), binwidth=2) + labs(x=NULL, y=NULL)
@
  \caption{Histograms of residuals, $\hat{\epsilon}$ for both the scatter plot (left) and the overlaid lines (right). Both appear to be normal, though there are some extreme outliers.}
    \label{residuals}
\end{figure}

Analysing the level one residuals, $\hat{\epsilon_{i}}$ and level two residuals, $\hat{\gamma_{i}}$ allows us to test the model fit as described \citet{Loy}. There are some negative extreme outliers but the distributional assumption appears to hold.

\begin{figure}[htbp]
  \centering
<<random, dependson='setup', fig.height=4, fig.width=6, out.width='0.7\\textwidth', echo=FALSE, warning=FALSE, message=FALSE, error=FALSE>>=
randomeffects <- summarise(group_by(prediction, subj_id), re=unique(diff))
ggplot(data=randomeffects) + geom_histogram(aes(x=re, y=..density..), binwidth=0.08) + xlab("Random Effects") + ylab(NULL)
@
    \caption{Histograms of estimated subject random effects, $\hat{\gamma}$. They appear to be normally distributed with mean zero.}
  \label{random}
\end{figure}

In Figure~\ref{random}, the level two residuals, $\hat{\gamma}$, generated appear to be normally distributed validating the assumptions of the modelling process.

The scores of each subject given by equation~\ref{score} can be summed to give a total score per subject $j$:

$${score}_{j} = \sum_{i}\{{score}_{ij} | i \in L_{j}\}$$

where $L_{j}$ is the set of lineups evaluated by subject $j$.

The lineup $i$ with $K$ evaluations has an expected score:

$${E[score]}_{i} = \frac{1}{K}\sum_{j}{score}_{ij}$$

summing these per subject gives an expected total score per subject:

$${E[score]}_{j} = \sum_{i}\{{E[score]}_{i} | i \in L_{j}\}$$

Finally, we measure visual ability by:

$${Visual Ability}_{j} = {score}_{j}-{E[score]}_{j}$$.

Comparing these to the estimated random effects $\hat\gamma$ in Figure~\ref{random2} shows that there is a strong correlation between visual ability and the random effects, further validating the model.

\begin{figure}[htbp]
\centering
<<random2, dependson='random', fig.height=6, fig.width=6, out.width='0.7\\textwidth', echo=FALSE, warning=FALSE, message=FALSE, error=FALSE>>=
ability <- merge(full.sub[,c("subj_id", "pic_id", "score", "weights")], bylineup.sub[c("pic_id", "percent")], by="pic_id")
ability <- summarise(group_by(ability, subj_id), actual=sum(score), estimated=sum(percent*weights))
ability$diff <- ability$actual - ability$estimated
ability.re <- merge(ability, randomeffects, by="subj_id")
ggplot(data=ability.re, aes(x=diff, y=re)) + geom_point() + labs(x="Visual Ability", y="Random Effects")
@
\caption{Visual ability plotted against random effects. The diagonal pattern suggests a strong positive relationship, indicating that the random effects in the model are a suitable measure of visual ability.}
\label{random2}
\end{figure}

\bibliographystyle{asa}
\bibliography{references}

\end{document}