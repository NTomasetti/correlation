\documentclass[12pt]{article}
\usepackage{natbib}
\usepackage{color}
\usepackage[dvipsnames,svgnames*]{xcolor}
\usepackage{array}
\usepackage[colorlinks=TRUE, linkcolor=blue]{hyperref}
\usepackage{wrapfig,float}
\usepackage[font=small,skip=5pt]{caption}
\usepackage{subcaption}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{dsfont}
\usepackage{amsthm}
\usepackage{amsfonts}
\usepackage{url}
\usepackage{ulem}
\usepackage[section]{placeins}
\usepackage{afterpage}
\usepackage{bbm}

\graphicspath{{images/}}
\DeclareGraphicsRule{.tif}{png}{.png}{`convert #1 `dirname #1`/`basename #1 .tif`.png}

\newtheorem{thm}{Theorem}[section]
\newtheorem{dfn}{Definition}[section]
\newtheorem{cor}{Corollary}[thm]
\newtheorem{con}{Conjecture}[thm]

% NOTE: To produce blinded version, replace "0" with "1" below.
\newcommand{\blind}{0}

\addtolength{\oddsidemargin}{-.5in}%
\addtolength{\evensidemargin}{-.5in}%
\addtolength{\textwidth}{1in}%
\addtolength{\textheight}{1.3in}%
\addtolength{\topmargin}{-.8in}%

\begin{document}

\def\spacingset#1{\renewcommand{\baselinestretch}%
{#1}\small\normalsize} \spacingset{1}

\if0\blind
{
\author{Nathaniel Tomasetti and Dianne Cook\\
Department of Econometrics and Business Statistics, Monash University\\
}
  \maketitle
} \fi
\if1\blind
{
  \bigskip
  \bigskip
  \bigskip
  \begin{center}
    {\LARGE\bf Supplementary Material: Comparing the Power of Plot Designs to Reveal Correlation}
\end{center}
  \medskip
} \fi

\tableofcontents

<<setup, echo=FALSE, results='asis', message=FALSE, error=FALSE, warning=FALSE>>=
library(maps)
library(ggplot2)
library(dplyr)
library(tidyr)
full <- read.csv("full.csv", row.names=1, stringsAsFactors = FALSE) ##MTurk evaluations
prediction <- read.csv("sas/predfit.csv") ##Large file, very slow, fitted data from SAS
time.fit <- read.csv("sas/time.csv") ##coefficients for time model from SAS
powercoef <- read.csv("sas/PowerEstimates.csv") ##coefficients for power model from SAS

full$subj_id <- factor(full$ip_address, labels=1:207)
y <- data.frame(table(full$subj_id))
keep <- y$Var1[y$Freq>9]
##Recording who evaluated at least ten lineups. Done prior to splitting multiple selections

full <- full %>% mutate(design = ifelse(test_param ==1, "Overlaid Lines", "Scatterplot"),
                         r = round(correlation, 1),
                         rsgn = ifelse(r >= 0, 1, 0),
                         rabs = abs(r),
                         alpha = log(0.05/0.95),
                         attempts = sapply(strsplit(as.character(full$response_0), ","), length), 
                         ##count number of selections in response_0 column
                         weights = 1/attempts) %>%
  transform(response_0= strsplit(as.character(response_0), ",")) %>% unnest(response_0) %>%
  ##split multiple selections in response_0 into different rows
  mutate(correct = ifelse(response_0 == actual_location, 1, 0), 
         score = ifelse(correct==1, (20-attempts)/19, 0)) %>%
  select(subj_id, correct, score, r, rsgn, rabs, smoothed, n, design, log_time, response_0,
         actual_location, pic_id, choice_reason, attempts, weights, alpha, conf_level)

full.sub <- filter(full, subj_id %in% keep) 
##keeping only subjects with >0 evaluations in actual modelling to better estimate random effects

bylineup <- summarise(group_by(full, pic_id, n, smoothed, design, r, actual_location), total=sum(score), correct=sum(correct), evals=sum(weights))
bylineup <- mutate(bylineup, percent = total/evals)
bylineup.sub <- summarise(group_by(full.sub, pic_id), total=sum(score), evals=sum(weights))
bylineup.sub <- mutate(bylineup.sub, percent = total/evals)

colnames(prediction) <- c("rabs", "t", "alpha", "rsgn", "smoothed", "design", "subj_id", "weights", "detected", "log_time", "RandomEf", "FixedEf", "residual")
prediction <- mutate(prediction, r = ifelse(rsgn==1, rabs, -rabs),
                     design = ifelse(design==0, "Overlaid Lines", "Scatterplot"), 
                     design = ifelse(smoothed==1, paste0(design, " (Smoothed)"), design),  
                     diff = round(RandomEf - FixedEf,5))
@

\section{Subject Demographics}

\begin{figure}[htbp]
\centering
<<map, dependson='setup', echo=FALSE, results='asis', message=FALSE, error=FALSE, warning=FALSE>>=
location <- read.csv("location.csv")
map.dat <- map_data("world")
ggplot() + geom_polygon(aes(long,lat, group=group), fill="grey65", data=map.dat) + theme_bw() +
  geom_point(data=location, aes(x=lon, y=lat, colour= "blue")) +scale_colour_manual(values=c("#FF5500", "#00FFFF")) + theme(aspect.ratio = 0.67, axis.text=element_blank(), axis.title=element_blank(), legend.position="none")
@
\caption{The location of the recruited subjects. The majority reside in North America but some are spread around other countries in Central America, Europe and Asia.}
\label{map}
\end{figure}

\begin{figure}[htbp]
\centering
<<users, dependson='setup', echo=FALSE, results='asis', message=FALSE, error=FALSE, warning=FALSE>>=
users <- read.csv("turk18_users.csv")
users$gender <- ifelse(users$gender==1, "Male", "Female")
ggplot(data=users, aes(x=factor(age), fill=factor(academic_study))) + geom_bar() + facet_wrap(~gender) +
  scale_fill_manual(values=c("#550000", "#883388", "#1133FF", "#FF9933", "#555555"))
@
\caption{Age and education by gender. Most subjects are in the younger brackets and there are more males than females}
\label{ageed}
\end{figure}


\section{Descriptive Statistics for Individuals}

\begin{figure}[htbp]
\centering
<<choices, dependson='setup', echo=FALSE, results='asis', message=FALSE, error=FALSE, warning=FALSE>>=
full.sub$choice_reason <-sapply(strsplit(as.character(unlist(full.sub$choice_reason)), "[^0-9]+"), "[[", 1)
ggplot(data=full.sub) + geom_bar(aes(x=choice_reason))
choice <- full.sub %>% transform(choice_reason= strsplit(as.character(choice_reason), "")) %>% unnest(choice_reason)
choice$rsgn <- factor(choice$rsgn, labels=c("r -","r +"))
choice$correct <- factor(choice$correct, labels=c("Did not detect", "Detected"))
ggplot(data=choice, aes(x=choice_reason, fill=correct)) + geom_bar() + facet_grid(design~rsgn) +
  theme(legend.position="bottom", axis.title=element_blank()) + scale_fill_discrete(name="True Plot")
@

\begin{figure}[htbp]
\centering 
<<avscore, dependson='setup', echo=FALSE, results='asis', message=FALSE, error=FALSE, warning=FALSE>>= 
subjplot <- summarise(group_by(full.sub, subj_id), eval=sum(weights), total = sum(score))
subjplot <- mutate(subjplot, avscore= total/eval)
ggplot(data=subjplot, aes(x=avscore)) + geom_histogram(binwidth=0.05)
@

\begin{figure}[htbp]
\centering
<<multiselect, dependson='setup', echo=FALSE, results='asis', message=FALSE, error=FALSE, warning=FALSE>>=
m.select <- summarise(group_by(subset(full.sub, attempts>1), subj_id, pic_id), attempts=max(attempts))
m.freq <- data.frame(table(m.select$pic_id))
m.lineup <- merge(m.freq, bylineup, by.x="Var1", by.y="pic_id")
ggplot(data=m.lineup) + geom_bar(aes(x=r, fill=plot), binwidth=0.2) + facet_grid(n~smoothed) + labs(y="Count", x="True plot correlation")
ggplot(data=subset(m.lineup, smoothed==1)) + geom_bar(aes(x=r, fill=plot), binwidth=0.2) + facet_wrap(~n)
@

\begin{table}
\caption{Number of selections per lineup evaluation. The subject with the most selections is reported.}
\label{tabattempts}
<<tabattempts, dependson='setup', echo=FALSE, results='asis', message=FALSE, error=FALSE, warning=FALSE>>=
attempts <- summarise(group_by(full.sub, subj_id, pic_id), attempts = max(attempts))
attempts.table <- data.frame(table(attempts$attempts))
attempts.table$most <- c(0,0,0,5,3,1,1)
colnames(attempts.table) <- c("Selections", "Whole Sample", "Subject 123")
kable(attempts.table, format="latex")
@
\end{table}


\begin{figure}[htbp]
\centering
<<multiattempts, dependson='setup', echo=FALSE, results='asis', message=FALSE, error=FALSE, warning=FALSE>>=
ggplot(data=attempts) + geom_bar(aes(x=as.factor(attempts))) + labs(x="Number of selections", y=NULL)
@
\caption{Histogram of table~\ref{attempts}}
\label{attempts}
\end{figure}


\section{Model Validation}

\begin{figure}
  \centering
<<residuals, dependson='setup', fig.height=4, fig.width=6, out.width='0.7\\textwidth', echo=FALSE, warning=FALSE, message=FALSE, error=FALSE>>=
glmm.resid <- subset(prediction, detected==0 | detected==1)
ggplot(data=glmm.resid) + geom_histogram(aes(y=..density.., x=residual), binwidth=2) + labs(x=NULL, y=NULL)
@
  \caption{Histograms of residuals, $\hat{\epsilon}$ for both the scatter plot (left) and the overlaid lines (right). Both appear to be normal, though there are some extreme outliers.}
    \label{residuals}
\end{figure}

Analysing the level one residuals, $\hat{\epsilon_{i}}$ and level two residuals, $\hat{\gamma_{i}}$ allows us to test the model fit as described \citet{Loy}. There are some negative extreme outliers but the distributional assumption appears to hold.

\begin{figure}[htbp]
  \centering
<<random, dependson='powermodel', fig.height=4, fig.width=6, out.width='0.7\\textwidth', echo=FALSE, warning=FALSE, message=FALSE, error=FALSE>>=
randomeffects <- summarise(group_by(prediction, subj_id), re=unique(diff))
ggplot(data=randomeffects) + geom_histogram(aes(x=re, y=..density..), binwidth=0.08) + xlab("Random Effects") + ylab(NULL)
@
    \caption{Histograms of estimated subject random effects, $\hat{\gamma}$. They appear to be normally distributed with mean zero.}
  \label{random}
\end{figure}

In Figure~\ref{random}, the level two residuals, $\hat{\gamma}$, generated appear to be normally distributed validating the assumptions of the modelling process.

The scores of each subject given by equation~\ref{score} can be summed to give a total score per subject $j$:

$${score}_{j} = \sum_{i}\{{score}_{ij} | i \in L_{j}\}$$

where $L_{j}$ is the set of lineups evaluated by subject $j$.

The lineup $i$ with $K$ evaluations has an expected score:

$${E[score]}_{i} = \frac{1}{K}\sum_{j}{score}_{ij}$$

summing these per subject gives an expected total score per subject:

$${E[score]}_{j} = \sum_{i}\{{E[score]}_{i} | i \in L_{j}\}$$

Finally, we measure visual ability by:

$${Visual Ability}_{j} = {score}_{j}-{E[score]}_{j}$$.

Comparing these to the estimated random effects $\hat\gamma$ in Figure~\ref{random2} shows that there is a strong correlation between visual ability and the random effects, further validating the model.

\begin{figure}[htbp]
\centering
<<random2, dependson='random', fig.height=6, fig.width=6, out.width='0.7\\textwidth', echo=FALSE, warning=FALSE, message=FALSE, error=FALSE>>=
ability <- merge(full.sub[,c("subj_id", "pic_id", "score", "weights")], bylineup.sub[c("pic_id", "percent")], by="pic_id")
ability <- summarise(group_by(ability, subj_id), actual=sum(score), estimated=sum(percent*weights))
ability$diff <- ability$actual - ability$estimated
ability.re <- merge(ability, randomeffects, by="subj_id")
ggplot(data=ability.re, aes(x=diff, y=re)) + geom_point() + labs(x="Visual Ability", y="Random Effects")
@
\caption{Visual ability plotted against random effects. The diagonal pattern suggests a strong positive relationship, indicating that the random effects in the model are a suitable measure of visual ability.}
\label{random2}
\end{figure}

\end{document}