\documentclass[12pt]{article}
\usepackage{natbib}
\usepackage{color}
\usepackage[dvipsnames,svgnames*]{xcolor}
\usepackage{array}
\usepackage[colorlinks=TRUE, linkcolor=blue]{hyperref}
\usepackage{wrapfig,float}
\usepackage[font=small,skip=5pt]{caption}
\usepackage{subcaption}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{dsfont}
\usepackage{amsthm}
\usepackage{amsfonts}
\usepackage{url}
\usepackage{ulem}
\usepackage[section]{placeins}
\usepackage{afterpage}
\usepackage{bbm}

\graphicspath{{images/}}
\DeclareGraphicsRule{.tif}{png}{.png}{`convert #1 `dirname #1`/`basename #1 .tif`.png}

\newtheorem{thm}{Theorem}[section]
\newtheorem{dfn}{Definition}[section]
\newtheorem{cor}{Corollary}[thm]
\newtheorem{con}{Conjecture}[thm]

% NOTE: To produce blinded version, replace "0" with "1" below.
\newcommand{\blind}{0}

\addtolength{\oddsidemargin}{-.5in}%
\addtolength{\evensidemargin}{-.5in}%
\addtolength{\textwidth}{1in}%
\addtolength{\textheight}{1.3in}%
\addtolength{\topmargin}{-.8in}%

\begin{document}

\def\spacingset#1{\renewcommand{\baselinestretch}%
{#1}\small\normalsize} \spacingset{1}

\title{\bf Supplementary Material: What is the Best Way to Display Two Time Series to Read Association?}

\if0\blind
{
\author{Nathaniel Tomasetti and Dianne Cook\\
Department of Econometrics and Business Statistics, Monash University\\
}
  \maketitle
} \fi
\if1\blind
{
  \bigskip
  \bigskip
  \bigskip
  \begin{center}
    {\LARGE\bf Supplementary Material: What is the Best Way to Display Two Time Series to Read Association?}
\end{center}
  \medskip
} \fi

\tableofcontents

<<setup, echo=FALSE, results='asis', message=FALSE, error=FALSE, warning=FALSE>>=
library(maps)
library(ggplot2)
library(dplyr)
library(tidyr)
full <- read.csv("data/full.csv", row.names=1, stringsAsFactors = FALSE) ##MTurk evaluations
prediction <- read.csv("data/predfit.csv") ##Large file, very slow, fitted data from SAS
time.fit <- read.csv("data/time.csv") ##coefficients for time model from SAS
powercoef <- read.csv("data/PowerEstimates.csv") ##coefficients for power model from SAS

full <- full %>% mutate(design = ifelse(test_param ==1, "Overlaid Lines", "Scatterplot"),
                         r = round(correlation, 1),
                         rsgn = ifelse(r >= 0, 1, 0),
                         rabs = abs(r),
                         alpha = log(0.05/0.95),
                         attempts = sapply(strsplit(as.character(full$response_0), ","), length), 
                         ##count number of selections in response_0 column
                         weights = 1/attempts)

full$subj_id <- factor(full$nick_name, labels=1:212)
y <- data.frame(table(full$subj_id))
keep <- y$Var1[y$Freq>9]
full.sub <- filter(full, subj_id %in% keep) 
full.sub <- Reduce(rbind, by(full.sub, full.sub$subj_id, head, n=10))
##Remove subjects with less than 10 evaluations. If more than 10, keep only first 10.

full <- full %>%  transform(response_0= strsplit(as.character(response_0), ",")) %>% unnest(response_0) %>%
  ##split multiple selections in response_0 into different rows
  mutate(correct = ifelse(response_0 == actual_location, 1, 0), 
         score = ifelse(correct==1, (20-attempts)/19, 0)) %>%
  select(subj_id, correct, score, r, rsgn, rabs, smoothed, n, design, log_time, response_0,
         actual_location, pic_id, choice_reason, attempts, weights, alpha, conf_level)

full.sub <- full.sub %>% transform(response_0= strsplit(as.character(response_0), ",")) %>% unnest(response_0) %>%
  mutate(correct = ifelse(response_0 == actual_location, 1, 0), 
         score = ifelse(correct==1, (20-attempts)/19, 0)) %>%
  select(subj_id, correct, score, r, rsgn, rabs, smoothed, n, design, log_time, response_0,
         actual_location, pic_id, choice_reason, attempts, weights, alpha, conf_level)

bylineup <- summarise(group_by(full, pic_id, n, smoothed, design, r, actual_location), total=sum(score), correct=sum(correct), evals=sum(weights))
bylineup <- mutate(bylineup, percent = total/evals)
bylineup.sub <- summarise(group_by(full.sub, pic_id), total=sum(score), evals=sum(weights))
bylineup.sub <- mutate(bylineup.sub, percent = total/evals)

colnames(prediction) <- c("rabs", "t", "alpha", "rsgn", "smoothed", "design", "subj_id", "weights", "detected", "log_time", "RandomEf", "FixedEf", "residual")
prediction <- mutate(prediction, r = ifelse(rsgn==1, rabs, -rabs),
                     design = ifelse(design==0, "Overlaid Lines", "Scatterplot"), 
                     design = ifelse(smoothed==1, paste0(design, " (Smoothed)"), design),  
                     diff = round(RandomEf - FixedEf,5))
@

\section{Lineup Results}

\begin{table}[htp]
\caption{The true plot detections / evaluations for each lineup in the data collection. Lineups with the same factor combination are seperated by row. Results ignore multiple selection and any removed evaluations. True plot correlation is on the x axis and t is on the y axis.}
\label{tabeval}
\centering
<<answertables, dependson='setup', echo=FALSE, results='asis', message=FALSE, error=FALSE, warning=FALSE>>=
turk.tbl <- select(bylineup, design, smoothed, r, n, correct, evals)
turk.tbl$result <- paste(round(turk.tbl$correct, 0), turk.tbl$evals, sep="/")
turk.tbl <- turk.tbl[order(turk.tbl$r, turk.tbl$n),]
scatter.uns <- data.frame(c(12, "", "", 24, "", "", 48, "", "", 96, "", ""), matrix(subset(turk.tbl, smoothed==0 & design=="Scatterplot")$result, ncol=8))
scatter.sm <- data.frame(c(12, "", "", 24, "", "", 48, "", "", 96, "", ""), matrix(subset(turk.tbl, smoothed==1 & design=="Scatterplot")$result, ncol=8))
line.uns <- data.frame(c(12, "", "", 24, "", "", 48, "", "", 96, "", ""), matrix(subset(turk.tbl, smoothed==0 & design=="Overlaid Lines")$result, ncol=8))
line.sm <- data.frame(c(12, "", "", 24, "", "", 48, "", "", 96, "", ""), matrix(subset(turk.tbl, smoothed==1 & design=="Overlaid Lines")$result, ncol=8))
colnames(scatter.uns) <- c("Unsmoothed Scatterplot", "-0.9", "-0.7", "-0.5", "-0.3", "0.3", "0.5", "0.7", "0.9")
colnames(scatter.sm) <- c("Smoothed Scatterplot","-0.9", "-0.7", "-0.5", "-0.3", "0.3", "0.5", "0.7", "0.9")
colnames(line.uns) <- c("Unsmoothed Overlaid Lines","-0.9", "-0.7", "-0.5", "-0.3", "0.3", "0.5", "0.7", "0.9")
colnames(line.sm) <- c("Smoothed Overlaid Lines","-0.9", "-0.7", "-0.5", "-0.3", "0.3", "0.5", "0.7", "0.9")
kable(scatter.uns, format="latex")
@
\end{table}
\begin{table}
\centering
<<answertables2, dependson='setup', echo=FALSE, results='asis', message=FALSE, error=FALSE, warning=FALSE>>=
kable(scatter.sm, format="latex")
@
\end{table}
\begin{table}
\centering
<<answertables3, dependson='setup', echo=FALSE, results='asis', message=FALSE, error=FALSE, warning=FALSE>>=
kable(line.uns, format="latex")
@
\end{table}
\begin{table}
\centering
<<answertables4, dependson='setup', echo=FALSE, results='asis', message=FALSE, error=FALSE, warning=FALSE>>=
kable(line.sm, format="latex")
@
\end{table}


\section{Subject Demographics}

\begin{figure}[htbp]
\centering
<<map, dependson='setup', echo=FALSE, results='asis', message=FALSE, error=FALSE, warning=FALSE, fig.height=3>>=
location <- read.csv("data/location.csv")
map.dat <- map_data("world")
ggplot() + geom_polygon(aes(long,lat, group=group), fill="grey65", data=map.dat) + theme_bw() +
  geom_point(data=location, aes(x=lon, y=lat, colour= "blue")) +scale_colour_manual(values=c("#FF5500", "#00FFFF")) + theme(aspect.ratio = 0.67, axis.text=element_blank(), axis.title=element_blank(), legend.position="none")
@
\caption{The location of the recruited subjects. The majority reside in North America but some are spread around other countries in Central America, Europe and Asia.}
\label{map}
\end{figure}

\begin{figure}[htbp]
\centering
<<users, dependson='setup', echo=FALSE, results='asis', fig.height=3, message=FALSE, error=FALSE, warning=FALSE>>=
users <- read.csv("data/turk18_users.csv")
users$academic_study <- factor(users$academic_study)
levels(users$academic_study) <- c("At Most High School", "Some Undergraduate", "Undergraduate Degree", "Some Postgraduate", "Postgraduate Degree")
users$age <- factor(users$age)
levels(users$age) <- c("18-25", "26-30", "31-35", "36-40", "41-45", "46-50", "51-55", "56-60", "61+")
ggplot(data=users, aes(x=age, fill=academic_study)) + geom_bar() + facet_wrap(~gender) +
  scale_fill_manual(name = element_blank(), values=c("#550000", "#883388", "#1133FF", "#FF9933", "#555555")) + labs(x="Age", y=element_blank()) + theme(axis.text.x = element_text(angle = 270))
@
\caption{Age and education by gender. Younger age brackets and males are over-represented in the sample, but these factors caused no significant impact on results.}
\label{ageed}
\end{figure}

Despite there being a wide range of subject demographics in the experiment recruited through Amazon's Mechanical Turk, age, gender, education and location all did not have a statistically significant effect on power of either plot design.  

Subjects are allowed to make multiple selections on each lineup evaluation, with a score for each evaluation defined by: 

\begin{equation}
\label{score}
{score}_{ij} =\frac{m-s_{ij}}{m-1} \mathbbm{I}_{ij}
\end{equation}

Where $m = 20$, the number of plots in a linup, $s_{ij}$ is the number of selections made by subject $i$ on lineup $j$ and $\mathbbm{I}_{ij} = 1$ if the true plot is detected, $0$ otherwise. The most selections made on any lineup evaluation is 8. No subject demographic had an increased rate of making multiple selections.

\begin{figure}[htbp]
\centering 
<<avscore, dependson='setup', echo=FALSE, results='asis', message=FALSE, error=FALSE, warning=FALSE, fig.height=4>>= 
subjplot <- summarise(group_by(full.sub, subj_id), eval=sum(weights), total = sum(score))
subjplot <- mutate(subjplot, avscore= total/eval)
ggplot(data=subjplot, aes(x=avscore)) + geom_histogram(binwidth=0.1)
@
\caption{The average score of our subjects, according to formula \ref{score}. There is a wide range of visual ability to be controlled with random effects in the modelling}
\label{avscore}
\end{figure}



\section{Evaluation Descriptive Statistics}

\begin{figure}[h]
\centering
<<choices, dependson='setup', echo=FALSE, results='asis', message=FALSE, error=FALSE, warning=FALSE, fig.height=4>>=
full$choice_reason <-sapply(strsplit(as.character(unlist(full$choice_reason)), "[^0-9]+"), "[[", 1)
choice <- full %>% transform(choice_reason= strsplit(as.character(choice_reason), "")) %>% unnest(choice_reason)
choice$rsgn <- factor(choice$rsgn, labels=c("r -","r +"))
choice$correct <- factor(choice$correct, labels=c("Did not detect", "Detected"))
choice$choice_reason <- factor(choice$choice_reason)
levels(choice$choice_reason) <- c("Close Together", "Matching Peaks", "Pattern Formed", "Formed a line", "Other")
ggplot(data=choice, aes(x=choice_reason, fill=correct)) + geom_bar() + facet_grid(design~rsgn) +
  theme(legend.position="bottom", axis.title=element_blank()) + scale_fill_discrete(name="True Plot")
@
\caption{Reasons given for plot selection. After controlling for lineup factors, there is no explanatory power.}
\label{reasons}
\end{figure}

We originally hypothesised that factor combinations with a low power are most likely to have multiple selections due to a decreased ability to differentiate between true and null plots. This would cause most lineups with multiple selection lineups to be concentrated around $\rho = \pm 0.3$ for both designs as well as any negative value for overlaid line graphs. Figure ~\ref{lineupmulti} plots lineups with at least one case of a subject selecting multiple plots in an evaluation. The hypothesised effect only appears at sample sizes of 48 and 96. The overlaid line graph lineups were more likely to have multiple selections, but this is also occuring in high positive correlations, where the power was similar to that of a scatter plot.

\begin{figure}[h]
\centering
<<multiselect, dependson='setup', echo=FALSE, results='asis', message=FALSE, error=FALSE, warning=FALSE, fig.height=4>>=
m.select <- summarise(group_by(subset(full.sub, attempts>1), subj_id, pic_id), attempts=max(attempts))
m.freq <- data.frame(table(m.select$pic_id))
m.lineup <- merge(m.freq, bylineup, by.x="Var1", by.y="pic_id")
ggplot(data=m.lineup) + geom_bar(aes(x=factor(r), fill=design)) + facet_grid(n~smoothed) + labs(y="Count", x="True plot correlation")
@
\caption{Characteristics of lineups with at least one subject making multiple selections. Overlaid line graph lineups have subjects make multiple selections more often, but true plot correlation does not appear to have an impact except at large sample sizes.}
\label{lineupmulti}
\end{figure}

\begin{table}[h]
\centering
\caption{Number of times $n$ selections from a lineup evaluation were made. The subject who made the most plot selections within their ten evaluations is additionally reported. There is no relationship between a subject's demographics and a likelihood to make multiple selections.}
\label{table}
<<tabattempts, dependson='setup', echo=FALSE, results='asis', message=FALSE, error=FALSE, warning=FALSE>>=
attempts <- summarise(group_by(full.sub, subj_id, pic_id), attempts = max(attempts))
attempts.table <- data.frame(table(attempts$attempts))
attempts.table$most <- c(0,0,0,5,3,1,1)
colnames(attempts.table) <- c("Selections", "Whole Sample", "Subject 123")
kable(attempts.table, format="latex")
@
\end{table}

\iffalse
\begin{figure}[htbp]
\centering
<<multiattempts, dependson='setup', echo=FALSE, results='asis', message=FALSE, error=FALSE, warning=FALSE, fig.height=4>>=
ggplot(data=attempts) + geom_bar(aes(x=as.factor(attempts))) + labs(x="Number of selections", y=NULL)
@
\caption{Histogram of table~\ref{table}}
\label{attemptshist}
\end{figure}
\fi

\section{Model Validation}

\begin{figure}[htbp]
  \centering
<<residuals, dependson='setup', fig.height=4, fig.width=6, out.width='0.7\\textwidth', echo=FALSE, warning=FALSE, message=FALSE, error=FALSE>>=
glmm.resid <- subset(prediction, detected==0 | detected==1)
ggplot(data=glmm.resid) + geom_histogram(aes(y=..density.., x=residual), binwidth=2) + labs(x=NULL, y=NULL)
@
  \caption{Histograms of residuals, $\hat{\epsilon}$ for both the scatter plot (left) and the overlaid lines (right). Both appear to be normal, though there are some extreme outliers.}
    \label{residuals}
\end{figure}

Analysing the level one residuals, $\hat{\epsilon_{i}}$, and level two residuals, $\hat{\gamma_{i}}$, allows us to test the model fit as described by \citet{Loy}. There are some extreme negative outliers but the distributional assumptions appear to hold.

\begin{figure}[htbp]
  \centering
<<random, dependson='setup', fig.height=4, fig.width=6, out.width='0.7\\textwidth', echo=FALSE, warning=FALSE, message=FALSE, error=FALSE>>=
randomeffects <- summarise(group_by(prediction, subj_id), re=unique(diff))
ggplot(data=randomeffects) + geom_histogram(aes(x=re, y=..density..), binwidth=0.08) + xlab("Random Effects") + ylab(NULL)
@
    \caption{Histograms of estimated subject random effects, $\hat{\gamma}$. They appear to be normally distributed with mean zero.}
  \label{random}
\end{figure}

In Figure~\ref{random}, the level two residuals, $\hat{\gamma}$, generated appear to be normally distributed validating the assumptions of the modelling process.

The scores of each subject given by equation~\ref{score} be summed to give a total score per subject $j$:

$${score}_{j} = \sum_{i}\{{score}_{ij} | i \in L_{j}\}$$

where $L_{j}$ is the set of lineups evaluated by subject $j$.

The lineup $i$ with $K$ evaluations has an expected score:

$$E[{score}_{i}] = \frac{1}{K}\sum_{j}{score}_{ij}$$

summing these per subject gives an expected total score per subject:

$$E[{score}_{j}]  = \sum_{i}\{E[{score}_{i}] | i \in L_{j}\}$$

Finally, we proxy visual ability by:

$${Visual Ability}_{j} = {score}_{j}-E[{score}_{j}] $$.

Comparing these to the estimated random effects $\hat\gamma$ in Figure~\ref{random2} shows that there is a strong correlation between visual ability and the random effects, further validating the model.

\begin{figure}[htbp]
\centering
<<random2, dependson='random', fig.height=6, fig.width=6, out.width='0.7\\textwidth', echo=FALSE, warning=FALSE, message=FALSE, error=FALSE>>=
ability <- merge(full.sub[,c("subj_id", "pic_id", "score", "weights")], bylineup.sub[c("pic_id", "percent")], by="pic_id")
ability <- summarise(group_by(ability, subj_id), actual=sum(score), estimated=sum(percent*weights))
ability$diff <- ability$actual - ability$estimated
ability.re <- merge(ability, randomeffects, by="subj_id")
ggplot(data=ability.re, aes(x=diff, y=re)) + geom_point() + labs(x="Visual Ability", y="Random Effects")
@
\caption{Visual ability plotted against random effects. The diagonal pattern suggests a strong positive relationship, indicating that the random effects in the model are a suitable measure of visual ability.}
\label{random2}
\end{figure}

\bibliographystyle{asa}
\bibliography{references}

\end{document}
